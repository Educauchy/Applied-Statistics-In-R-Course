?lillie.test
??lillie.test
lillie.test(n, "pnorm")
library(nortest)
?lillie.test
lillie.test(n)
# 2
n <- read.csv(file = paste0(path, "Task2.csv"), header = F, dec = ".", sep = ";")$V1
hist(n, xlab = "Value", breaks = 10, main = "Histogram of the dataset")
ks.test(n, "pnorm")
# 2
n <- read.csv(file = paste0(path, "Task2.csv"), header = F, dec = ".", sep = ";")$V1
Sys.setlocale(category = "LC_ALL", locale = "UTF-8")
path <- "~/Yandex.Disk.localized/Университет/Магистратура/2semester/R/Exam/Datasets/"
library(ggpubr)
library(EnvStats)
library(nortest)
library(NbClust)
library(factoextra)
library(cluster)
library(ridge)
library(psych)
library(aod)
library(glmnet)
library(quantreg)
library(MASS)
#Elbow Method for finding the optimal number of clusters
elbow <- function(data) {
set.seed(123)
# Compute and plot wss for k = 2 to k = 15.
k.max <- 15
wss <- sapply(1:k.max,
function(k) {
kmeans(data, k, nstart=50, iter.max = 15)$tot.withinss
})
wss
plot(1:k.max, wss,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
}
# Mode function
mode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
# 1
v <- read.csv(file = paste0(path, "Task1.csv"), header = F, dec = ".", sep = ";")$V1
summary(v)
stat <- describe(v)
stat
mode(v)
plot(ecdf(v), xlab = "Value", main = "Cumulative distribution function")
ggboxplot(v, main = "Boxplot diagram of the dataset")
hist(v, xlab = "Value", breaks = 3, main = "Histogram of the dataset with 2 breaks")
hist(v, xlab = "Value", breaks = 6, main = "Histogram of the dataset with 6 breaks")
hist(v, xlab = "Value", breaks = 9, main = "Histogram of the dataset with 12 breaks")
# 2
n <- read.csv(file = paste0(path, "Task2.csv"), header = F, dec = ".", sep = ";")$V1
hist(n, xlab = "Value", breaks = 10, main = "Histogram of the dataset")
ks.test(n, "pnorm")
lillie.test(n)
lillie.test(rnorm(100, mean = 5, sd = 3))
lillie.test(runif(100, min = 2, max = 4))
lillie.test(runif(100, min = 2, max = 4))
lillie.test(runif(100, min = 2, max = 4))
lillie.test(runif(100, min = 2, max = 4))
lillie.test(runif(100, min = 2, max = 4))
lillie.test(runif(100, min = 2, max = 4))
lillie.test(runif(100, min = 2, max = 4))
lillie.test(runif(100, min = 2, max = 4))
lillie.test(runif(100, min = 2, max = 4))
# 4-2
bin <- read.csv(file = paste0(path, "Task4-2.csv"), header = T, dec = ".", sep = ",")
model_logit <- glm(Y ~ ., data = bin, family = binomial("logit"))
summary(model_logit)
# 4-2
bin <- read.csv(file = paste0(path, "Task4-2.csv"), header = T, dec = ".", sep = ",")
model_logit <- glm(Y ~ ., data = bin, family = binomial("logit"))
summary(model_logit)
wald.test(b = coef(model_logit), Sigma = vcov(model_logit), Terms = 1:4) # p-value = 0.15 > 0.05 => not significant
?wald.test
wald.test(b = coef(model_logit), Sigma = vcov(model_logit), Terms = 2:4) # p-value = 0.15 > 0.05 => not significant
wald.test(b = coef(model_logit), Sigma = vcov(model_logit), Terms = 1:4) # p-value = 0.15 > 0.05 => not significant
wald.test(b = coef(model_logit), Sigma = vcov(model_logit), Terms = 1:4) # p-value = 0.15 > 0.05 => not significant
data(orob2)
fm <- quasibin(cbind(y, n - y) ~ seed * root, data = orob2)
# Wald test for the effect of root
wald.test(b = coef(fm), Sigma = vcov(fm), Terms = 3:4)
